diff --git a/mlflow/environment_variables.py b/mlflow/environment_variables.py
index b29d67c99..3ae923ee9 100644
--- a/mlflow/environment_variables.py
+++ b/mlflow/environment_variables.py
@@ -121,6 +121,10 @@ MLFLOW_S3_IGNORE_TLS = _BooleanEnvironmentVariable("MLFLOW_S3_IGNORE_TLS", False
 #: (default: ``None``)
 MLFLOW_S3_UPLOAD_EXTRA_ARGS = _EnvironmentVariable("MLFLOW_S3_UPLOAD_EXTRA_ARGS", str, None)

+MLFLOW_S3_UPLOAD_CHUNK_SIZE = _EnvironmentVariable("MLFLOW_S3_UPLOAD_CHUNK_SIZE", int, None)
+
+MLFLOW_S3_DOWNLOAD_CHUNK_SIZE = _EnvironmentVariable("MLFLOW_S3_DOWNLOAD_CHUNK_SIZE", int, None)
+
 #: Specifies the location of a Kerberos ticket cache to use for HDFS artifact operations.
 #: (default: ``None``)
 MLFLOW_KERBEROS_TICKET_CACHE = _EnvironmentVariable("MLFLOW_KERBEROS_TICKET_CACHE", str, None)
diff --git a/mlflow/store/artifact/s3_artifact_repo.py b/mlflow/store/artifact/s3_artifact_repo.py
index e3d11760b..e2492149b 100644
--- a/mlflow/store/artifact/s3_artifact_repo.py
+++ b/mlflow/store/artifact/s3_artifact_repo.py
@@ -8,7 +8,9 @@ import urllib.parse

 from mlflow.entities import FileInfo
 from mlflow.environment_variables import (
+    MLFLOW_S3_DOWNLOAD_CHUNK_SIZE,
     MLFLOW_S3_UPLOAD_EXTRA_ARGS,
+    MLFLOW_S3_UPLOAD_CHUNK_SIZE,
     MLFLOW_S3_ENDPOINT_URL,
     MLFLOW_S3_IGNORE_TLS,
 )
@@ -106,6 +108,9 @@ class S3ArtifactRepository(ArtifactRepository):
         self._secret_access_key = secret_access_key
         self._session_token = session_token

+        self._download_chunk_size = MLFLOW_S3_DOWNLOAD_CHUNK_SIZE.get()
+        self._upload_chunk_size = MLFLOW_S3_UPLOAD_CHUNK_SIZE.get()
+
     def _get_s3_client(self):
         return _get_s3_client(
             access_key_id=self._access_key_id,
@@ -144,7 +149,20 @@ class S3ArtifactRepository(ArtifactRepository):
         environ_extra_args = self.get_s3_file_upload_extra_args()
         if environ_extra_args is not None:
             extra_args.update(environ_extra_args)
-        s3_client.upload_file(Filename=local_file, Bucket=bucket, Key=key, ExtraArgs=extra_args)
+
+        from boto3.s3.transfer import TransferConfig
+
+        config = TransferConfig()
+        if self._upload_chunk_size:
+            config.multipart_chunksize = self._upload_chunk_size
+
+        s3_client.upload_file(
+            Filename=local_file,
+            Bucket=bucket,
+            Key=key,
+            ExtraArgs=extra_args,
+            Config=config,
+        )

     def log_artifact(self, local_file, artifact_path=None):
         (bucket, dest_path) = data_utils.parse_s3_uri(self.artifact_uri)
@@ -220,7 +238,20 @@ class S3ArtifactRepository(ArtifactRepository):
         (bucket, s3_root_path) = data_utils.parse_s3_uri(self.artifact_uri)
         s3_full_path = posixpath.join(s3_root_path, remote_file_path)
         s3_client = self._get_s3_client()
-        s3_client.download_file(bucket, s3_full_path, local_path)
+
+        from boto3.s3.transfer import TransferConfig
+
+        config = TransferConfig()
+        if self._download_chunk_size:
+            config.multipart_chunksize = self._download_chunk_size
+
+        config = boto3.s3.transfer.TransferConfig()
+        s3_client.download_file(
+            Bucket=bucket,
+            Key=s3_full_path,
+            Filename=local_path,
+            Config=config,
+        )

     def delete_artifacts(self, artifact_path=None):
         (bucket, dest_path) = data_utils.parse_s3_uri(self.artifact_uri)
